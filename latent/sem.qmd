---
title: "Structural Equation Models"
---

Structural Equation Models (SEM) allow us to combine measurement models (ex. factor anlaysis) with Linear regression models between the latent variables.

::: center-graph
```{dot}
//| fig-width: 6
//| fig-height: 1.2
digraph example2 {
  bgcolor="transparent";
  // Nodes
  F1 [shape=box, pos = "0,0!", label="Latent Explanatory Variable"]
  X1 [shape=box, pos = "2,0!", label="Item 1 (X1)"]
  X2 [shape=box, pos = "1,-2!", label="Item 2 (X2)"]
  X3 [shape=box, pos="1,0!", label="Item 3 (X3)"]
  F2 [shape=box, pos = "0,0!", label="Latent Response Variable"]
  X4 [shape=box, pos = "2,0!", label="Item (Y1)"]
  X5 [shape=box, pos = "1,-2!", label="Item (Y2)"]
  X6 [shape=box, pos="1,0!", label="Item (Y3)"]

  // Edges
  {F1 -> X1 [label=<<FONT FACE="Arial">&lambda;</FONT>>]}
  {F1 -> X2 [label=<<FONT FACE="Arial">&lambda;</FONT>>]}
  {F1 -> X3 [label=<<FONT FACE="Arial">&lambda;</FONT>>]}
  {F2 -> X4 [label=<<FONT FACE="Arial">&lambda;</FONT>>]}
  {F2 -> X5 [label=<<FONT FACE="Arial">&lambda;</FONT>>]}
  {F2 -> X6 [label=<<FONT FACE="Arial">&lambda;</FONT>>]}
  {rank=same; F1 -> F2 [label="Linear Model"]}
  
  graph [nodesep=0.5, ranksep=0.5]

}
```
:::

::: small
This is an example of a very simple structural equation model.
:::

This structural equation model contains a linear regression between the latent input variable explaining the latent outcome variable.

$$
\Y = \alpha +  \beta\ \X + \eps
$$

The latent outcome variable and input variable are explained by measurement models (typically a factor analysis model):

$$
\begin{align}
\text{input.item}_i & = \tau_\text{input} + \lambda_{i} \ \X + \eps_\text{input} \\
\text{outcome.item}_j & = \tau_\text{outcome} + \lambda_j \ \X + \eps_\text{outcome}
\end{align}
$$

The interpretations of the model are quite straight forward - the measurment models are interpreted in the same way as factor analysis, and the linear model between latent variable is interpreted the same way as a linear model between any other variables.

::: small
For example, the linear model says that as explanatory increases by 1, response increases by an expected $\beta$ units.
:::

Structural models don't have to have just one dependent and independent latent variable. We can have multiple dependent and independent variables, multiple linear models, and also measure correlations within the dependent and independent variables:

::: center-graph
```{dot}
//| fig-width: 5
//| fig-height: 1.3
digraph example2 {
  bgcolor="transparent";
  // Nodes
  X1 [shape=box, label="Latent Independent Variable 1"]
  X2 [shape=box, label="Latent Independent Variable 2"]
  Y1 [shape=box, label="Latent Dependent Variable 1"]
  Y2 [shape=box, label="Latent Dependent Variable 2"]

  // Edges
  {rank=same; X1 -> Y1 [label = "Model"]}
  {rank=same; X2 -> Y2 [label = "Model"]}
  X1 -> Y2 [label = "Model"]
  X2 -> Y1 [label = "Model"]
  X1 -> X2 [dir=both, label = "Correlation"]
  Y1 -> Y2 [dir=both, label = "Correlation"]
  
  graph [nodesep=0.5, ranksep=0.5]

}
```
:::

::: small
Note: we cannot have linear models between two independent, or two dependent variables. They have to be seperate - within each group, only correlations are possible.
:::

In this example, we are measuring the correlation between the independent variables, the correlation between the dependent variables, and we have two regression models:

$$
\begin{align}
\Y_1 & = \beta_0 + \beta_1\ \X_1 + \beta_2\ \X_2 + \eps_1 \\
\Y_2 & = \gamma_0 + \gamma_1\ \X_1 + \gamma_2\ \X_2 + \eps_2 \\
\end{align}
$$

::: small
And each response and latent variable all have their own measurement models.
:::

<br />

To implement structural equation models, we use the **lavaan** package:

```{r, eval = F}
library(lavaan)
```

Then, we have to specify the relationships between variables we want to fit in our structural model - including measurement models, regression models, and correlations:

```{r, eval = F}
model <- '
# Measurement models 
  input1 =~ NA*item1 + item2 + item3
  input2 =~ NA*item4 + item5 + item6
  outcome =~ item1 + item2 + item3
  
# Regressions
  outcome ~ input1 + input2

# Covariances
  input1 ~~ input2

# Fixing the variances of independent variables at 1
  input1~~1*input1
  input2~~1*input2
'
```

::: small
Note how outcome does not have NA\*, and outcome doesn't have its variance fixed at 1 at the end. Meanwhile, input1 and input2 do. This is standard to fix outcome variables with a variance of 1, and input variables are allowed to be "free".
:::

Now, we estimate our specified model:

```{r, eval = F}
sem <- sem(model,
           data = my_data,
           missing="FIML")
summary(sem)
```

::: small
The missing argument tells the software to keep observations with missing values (this is typically a good thing). But it can take longer, so you can delete this argument for it to use only complete observations.
:::
