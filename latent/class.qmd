---
title: "Latent Class Model"
---

Latent class models are an extension of factor analysis, that deals with cases of a categorical latent variable with categorical/binary observed items.

::: center-graph
```{dot}
//| fig-width: 4.5
//| fig-height: 1.4
digraph example2 {
  bgcolor="transparent";
  // Nodes
  F [shape=box, pos = "0,0!", label=<<FONT FACE="Helvetica">&xi; (Unobserved)</FONT>>]
  X1 [shape=box, pos = "2,0!", label="X1 (Observed)"]
  X2 [shape=box, pos = "1,-2!", label="X2 (Observed)"]
  X3 [shape=box, pos="1,0!", label="X3 (Observed)"]

  // Edges
  {F -> X1 [label=<<FONT FACE="Helvetica">&lambda;</FONT>>]}
  {F -> X2 [label=<<FONT FACE="Helvetica">&lambda;</FONT>>]}
  {F -> X3 [label=<<FONT FACE="Helvetica">&lambda;</FONT>>]}
  
  graph [nodesep=0.5, ranksep=0.5]

}
```
:::

The factors a categorical variable, which each category $c$ called a **latent class**. We also have categorical observed items. The latent class models connects each item with a factor through a **item response probability**:

$$
\begin{align}
& Pr(X_1 = \text{category }k_i \ | \ \xi = \text{category }c)\\
& Pr(X_2 = \text{category }k_i  \ | \ \xi = \text{category }c)\\
& Pr(X_3 = \text{category }k_i  \ | \ \xi = \text{category }c)\\
\end{align}
$$

::: small
$k_1$ is one specific category of item $1$, same for $k_2$ for item $2$, and so on. $c$ is one specific category of the factor.
:::

We also have another part of the measurement mode, the **structural model**, which determines the probability of each category in the factor:

$$
\alpha_c = Pr(\xi=\text{category }c)
$$

Interpretation of the latent factor depends on the item response probabilities. Below, the columns are the different classes/categories of the factor, and the big rows are each item.

![](images/clipboard-3462056940.png){fig-align="center" width="80%"}

The first class (the first column) has the highest probabilities if individuals *never worry* about crime, *no real effect* on quality of life, *never* worry about burglary, and *no real effect* on quality of life. Thus, we can conclude this first category of the latent variable is something like - *not worried about crime*.

The second class (the 2nd column), where the top responses have the highest probabilities except for the frequency of worry about burglaries - where the probabilities are highest for *some of the time* and *just occasionally*. This suggests that this second category is measuring something like - only worried about burglary, and no other crime.

We can also create factor scores - which is a little different, because now we are basically assigning every unit in our data to a category of the latent factor. This is done by calculating the posterior probability of being in each class:

$$
\widehat{Pr}(\xi = \text{category }c \ | \ X_1 = \text{category }k_1, X_2 = \text{category }k_2, \dots )
$$

We calculate this probability for all categories $c$ in the factor. Whichever category $c$ of the latent variable has the highest probability, is the category a unit is assigned to.

::: small
This can be considered quite similar to that of cluster analysis, which will be introduced later.
:::

<br />

To implement latent class models, we will need the **polLCA** package:

```{r, eval = F}
library(poLCA)
```

This package requires that our categories of items are labelled starting with 1. This means if you have a binary variable of 0 and 1, you will need to change it to 1 and 2.

To begin, we will first need to create a vector of our item names:

```{r, eval = F}
vars <- c("item1","item2","item3","item4")
```

Then, let us fit our model as follows:

```{r, eval = F}
form <- cbind(item1, item2, item3, item4) ~1
model <- poLCA(form,
              my_data[,vars],
              nclass = 2, #number of categories for factor
              na.rm = F,
              nrep = 10) 
```

::: small
na.rm = F means to include missing values when estimating (which is recommended). nrep = 10 indicates how many times to run the gradient descent algorithm - more is better, but will take longer.
:::

The traditional output is hard to read, so we will use a function:

```{r, eval = F}
# function
LCA.probs <- function(res){
  probs <- res$probs
  item.p <- NULL
  for(i in seq_along(probs)){
        m.tmp <- t(probs[[i]])
        rownames(m.tmp) <- paste(names(probs)[i],colnames(probs[[i]]),sep=".")
        item.p <- rbind(item.p,m.tmp)
  }
  item.p <- round(item.p,3)
  class.p <- res$P
  names(class.p) <- colnames(item.p)
  list(item.probabilities=item.p,class.probabilities=class.p)
}

# output results
LCA.probs(model)
```

We can calculate factor scores/classification as follows:

```{r, eval = F}
model$predclass
```

We can choose our model based on the AIC or BIC score.

```{r, eval = F}
model$aic
model$bic
```
