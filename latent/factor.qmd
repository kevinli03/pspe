---
title: "Factor Analysis Model"
---

Factor analysis is a way to model a continuous latent variable, based on a bunch of continuous observed items.

::: center-graph
```{dot}
//| fig-width: 4
//| fig-height: 1.4
digraph example2 {
  bgcolor="transparent";
  // Nodes
  F [shape=box, pos = "0,0!", label="Latent Factor (F)"]
  X1 [shape=box, pos = "2,0!", label="Item 1 (X1)"]
  X2 [shape=box, pos = "1,-2!", label="Item 2 (X2)"]
  X3 [shape=box, pos="1,0!", label="Item 3 (X3)"]

  // Edges
  {F -> X1 [label=<<FONT FACE="Arial">&lambda;</FONT>>]}
  {F -> X2 [label=<<FONT FACE="Arial">&lambda;</FONT>>]}
  {F -> X3 [label=<<FONT FACE="Arial">&lambda;</FONT>>]}
  
  graph [nodesep=0.5, ranksep=0.5]

}
```
:::

The factor is the unobserved latent variable we want to measure. We assume that the factor is continuous, and normally distributed:

$$
\F \sim \mathcal N(0, 1)
$$

::: small
Where $\kappa = 0$ is the mean of the factor, and $\phi =1$ is the variance of the factor. Technically, the factor only needs to be normally distributed - we can have different means and variances. However, for identification reasons, we typically fix the factor to a standard normal.
:::

The $p$ number of items are the variables we observe, that we believe are a measurement of the latent factor. Factor analysis assumes that each observed item is associated with the latent factor with a **linear regression model**:

$$
\begin{align}
\I_1 & = \tau_1 + \lambda_1 \ \F + \delta_1 \\
\I_2 & = \tau_2 + \lambda_2 \ \F + \delta_2 \\
& \vdots \qquad \qquad \vdots \\
\I_p & = \tau_p + \lambda_p \ \F + \delta_p
\end{align}
$$

-   $\tau_i$ is the intercept of the model.
-   $\lambda_i$ is the coefficient that describes the relationship between any item and the factor. These are called **factor loadings**.
-   $\delta_i$ is the error term - the part of an item not explained by the factor. They are called the **unique factors**.

::: small
We assume that the error terms are normally distributed $\delta_i \sim \mathcal N(0, \theta_{ii})$, that the different error terms $\delta_1, \dots, \delta_p$ are uncorrelated with each other, and factor is uncorrelated with the errors (exogeneity).
:::

The factor loadings $\lambda_i$ represent the relationship/**covariance** between any item and a factor. If the items have been standardised to a standard normal, then $\lambda_i$ is also the correlation coefficient between items and factor.

::: small
Note: this isn't entirely true for multiple factors, as we will discuss in a later page.
:::

These factor loadings help us interpret our latent variable. The sign of the factor loading tells us the direction in which our latent variable is measuring. The absolute size of the factor loading tells us how important that item is to the factor.

::: {.callout-note collapse="true" appearance="simple"}
## Interpretation Example

This is a typical output of factor anlaysis. ML1 and ML2 are the two factors (let us focus on just ML1), and the rows are items (which are trust in different institutions).

![](images/clipboard-3872288459.png){width="75%"}

For factor 1 (ML1), we can see that *pol_parties*, *politicians* have very large loadings. *EP, parliament, and UN* have moderate loadings. *Police* and *legal* have almost 0 loadings. Almost all loadings are positive.

This tells us that factor 1 is a latent variable that measures mostly trust in politicians, rather than the legal/policing system. Since the loadings are almost all positive, we can conclude that higher values of factor 1 mean higher levels of trust in legal/policing systems.
:::

We can conduct hypothesis testing with each factor loading $\lambda$ with a **z-test**. The null hypothesis is that $\lambda = 0$, and the alternate hypothesis is that $\lambda â‰  0$. If the p-value is less than 0.05, we know that there is a relationship between that item and the factor.

<br />

To implement factor analysis, we will need the **psych** and **GPArotation** package:

```{r, eval = F}
library(psych)
library(GPArotation)
```

First, we should get rid of missing observations:

```{r, eval = F}
all.obs <- apply(my_data, 1, FUN=function(x){all(!is.na(x))})
dta <- my_data[all.obs,]
```

For factor analysis with one factor, we use the syntax:

```{r, eval = F}
fa <- fa(data[,items], nfactors=1, fm="ml")
print(fa1)
```
