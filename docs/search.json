[
  {
    "objectID": "randomisation.html",
    "href": "randomisation.html",
    "title": "The Magic of Randomisation",
    "section": "",
    "text": "This chapter covers how randomisation solves the problem of selection bias, and why randomisation is considered the “gold standard” of causal inference.\n\nLet us say we are interested in this question:\n\n\n\n\n\n\n\n\nexample1\n\n\n\nD\n\nScholarship (D)\n\n\n\nY\n\nUniversity Performance (Y)\n\n\n\nD-&gt;Y\n\n\nCausal Effect\n\n\n\n\n\n\n\n\n\nOur concern is a confounder. For example, smartness of an individual could mean they are more likely to get a scholarship. Since smart people tend to perform well at university, that means the people who get treated are different from those who don’t get treated.\n\n\n\n\n\n\n\n\nexample2\n\n\n\nD\n\nScholarship (D)\n\n\n\nY\n\nUniversity Performance (Y)\n\n\n\nD-&gt;Y\n\n\nCausal Effect\n\n\n\nX\n\nSmartness (Confounder)\n\n\n\nX-&gt;D\n\n\n\n\n\nX-&gt;Y\n\n\n\n\n\n\n\n\n\n\n\n\n\nSmartness is not the only confounder. Other confounders could be family income, athletic ability, etc.\n\nBut what if randomness (like flipping a coin) controls who gets the treatment or not. A coin will be flipped to decide if every person in our study will get the scholarship. This means that the randomness (the coin), and not the confounder, are causing selection into treatment:\n\n\n\n\n\n\n\n\nexample2\n\n\n\nD\n\nScholarship (D)\n\n\n\nY\n\nUniversity Performance (Y)\n\n\n\nD-&gt;Y\n\n\nCausal Effect\n\n\n\nX\n\nSmartness (Confounder)\n\n\n\nX-&gt;Y\n\n\n\n\n\n\nO\n\nCoin\n\n\n\nO-&gt;D\n\n\n\n\n\n\n\n\n\n\n\nSince the confounder is no longer causing who gets the treatment and who doesn’t, that means there is no more concern of selection bias.\n\nRandomisation also means that every individual has the same chance of being treated or untreated, so the two groups will, on average, the same as each other. That means:\n\\[\n\\textcolor{purple}{\\mean Y_\\text{untreated}^{(0)}} = \\textcolor{red}{\\mean Y_\\text{treated}^{(0)}}, \\text{ so correlation} = \\text{causation}\n\\]\n\nThis is established by the law of large numbers, but it is a little technical for here.\n\nSo if our treatment is randomly assigned (individuals randomly assigned to treatment or control), correlation does equal causation.\n\nRandomisation is the gold standard of causal inference. There is no better method.\n\nRandomisation is possible if you are running your own experiment: you can use a random number generator to assign treatment.\nRandomisation is also possible if there is something that is being randomly assigned in the real world. For example, the US green card lottery randomly chooses who gets accepted.\n\nHowever, randomisation is not always possible to due to cost of running experiments, non-compliance of individuals within experiments, and impracticality.\n\nNon-compliance is an issue that can be solved pretty easily with an instrumental variable, given a few assumptions about the non-compliance.",
    "crumbs": [
      "Home",
      "Magic of Randomisation"
    ]
  },
  {
    "objectID": "correlation.html",
    "href": "correlation.html",
    "title": "Basics of Causality",
    "section": "",
    "text": "This page covers how confounders cause pre-existing differences between treated and untreated (selection bias), meaning correlation is not causation.\n\nLet us look at this causal question:\n\n\n\n\n\n\n\n\nexample1\n\n\n\nD\n\nGoing to the Hospital (D)\n\n\n\nY\n\nHealth Outcomes (Y)\n\n\n\nD-&gt;Y\n\n\nCausal Effect\n\n\n\n\n\n\n\n\n\nWe have a treated group (went to hospital), and an untreated group. Using our potential outcomes framework, we can define the treatment effect of the treated group:\n\\[\n\\tau_\\text{treated} = \\textcolor{purple}{\\mean Y_{\\text{treated}}^{(1)}} - \\textcolor{red}{\\mean Y_{\\text{treated}}^{(0)}}\n\\]\n\nIn red is the counterfactual we do not observe.\n\nNow compare the treatment effects above to correlation, which is defined as the difference in observed outcomes:\n\\[\n\\begin{align}\n\\text{correlation} & = \\mean Y_\\text{treated} - \\mean Y_\\text{untreated} \\\\\n& = \\textcolor{purple}{\\mean Y_{\\text{treated}}^{(1)}} - \\textcolor{purple}{\\mean Y_\\text{untreated}^{(0)}}\n\\end{align}\n\\]\nIf we compare this correlation to our \\(\\tau_\\text{treated}\\), we see:\n\\[\n\\text{if  } \\textcolor{purple}{\\mean Y_\\text{untreated}^{(0)}} ≠ \\textcolor{red}{\\mean Y_\\text{treated}^{(0)}}, \\text{ then }  \\tau_\\text{treated} ≠ \\text{correlation}\n\\]\n\nThese two quantities are potential outcomes under control, or in another way to think of it, outcomes of the two groups prior to treatment happening.\n\nThus, if there is a difference between the average outcomes between treated and untreated before treatment is administered, then correlation is not equal to causation. This is because we cannot tell if the difference between the groups is due to treatment, or due to their pre-existing differences.\n\nWhat causes pre-existing differences? Confounders. For example, in our hospital-health example, a confounder could be smoking.\n\nSmoking is not the only possible confounder, we just use it as an example. Drinking, age, etc. are all other potential confounders.\n\nSmoking will worsen health outcomes. Someone who smokes is also more likely to visit the hospital with health complications. That means people who go to the hospital start out with (on average) worse health outcomes than people who did not go to the hospital.\n\n\n\n\n\n\n\n\nexample2\n\n\n\nD\n\nGoing to the Hospital (D)\n\n\n\nY\n\nHealth Outcomes (Y)\n\n\n\nD-&gt;Y\n\n\nCausal Effect\n\n\n\nX\n\nSmoking (Confounder)\n\n\n\nX-&gt;D\n\n\n\n\n\nX-&gt;Y\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA confounder is a third variable that has the following characteristics:\n\nThe confounder is correlated (positive or negative) with the outcome variable.\nThe confounder causes who gets and doesn’t get the treatment.\nThe confounder is not itself caused by the treatment\n\n\n\n\n\nNote requirement 3 - it is a common mistake. Any result of the treatment \\(D\\) cannot be a confounder.\n\nConfounders cause pre-existing differences, which cause correlation to not equal causation. We must account for confounders to uncover causal effects.",
    "crumbs": [
      "Home",
      "Issue of Selection Bias"
    ]
  },
  {
    "objectID": "pscore.html",
    "href": "pscore.html",
    "title": "Propensity Score Matching",
    "section": "",
    "text": "See the pros and cons of this estimator in the choosing an estimator page.\n\nMia is in our study and receives the treatment. Mia’s causal effect is:\n\\[\n\\tau_{\\text{Mia}} = \\textcolor{purple}{Y^{(1)}_\\text{Mia}} - \\textcolor{red}{Y^{(0)}_\\text{Mia}}\n\\]\nWe cannot observe Mia’s counterfactual (in red). However, what we can do is to find an untreated individual similar to Mia to approximate Mia’s counterfactual:\n\\[\n\\tau_{\\text{Mia}} \\approx \\textcolor{purple}{Y^{(1)}_\\text{Mia}} - \\textcolor{purple}{Y^{(0)}_\\text{Matched individual}}\n\\]\nPropensity Score Matching matches an individual that is treated (like Mia) with one that is not treated based on how similar their likelihoods of treatment are.\nWhat is a likelihood of treatment? Well we know confounders cause people to get the treatment or not treatment. Thus, using an individual’s confounder values, we can estimate their likelihood of getting treatment, called a propensity score.\n\\[\n\\text{propensity score } \\pi =Pr(\\text{you get treated})\n\\]\nPropensity scores are typically estimated with a logistic regression:\n\\[\n\\log\\left( \\frac{\\pi(\\b X_i)}{1- \\pi(\\b X_i)}\\right) = \\alpha + \\b X_i' \\b\\beta\n\\]\nThis also means that propensity score matching shares the same weaknesses of logistic regression - including assuming linear relatinoships between confounders and propensities, and only being unbiased in large sample sizes.\n\nBefore you implement propensity score matching, make sure you have reasons to believe you meet the neccessary assumptions for selection on observables:\nWe will need the Matching package.\n\nlibrary(Matching)\n\nFirst, we need to estimate the propensity scores with a logistic regression:\n\npropensity &lt;- glm(D ~ X1 + X2,\n                  data = my_data,\n                  family = \"binomial\")\nmy_data$pscore &lt;- predict(propensity,\n                          type = \"response\")\n\n\nA random forest model is also possible, but less common.\n\nNow, we can implement the matching as follows.\n\natt &lt;- Match(Y = my_data$Y,\n             Tr = my_data$D,\n             X = my_data[,\"pscore\"],\n             M = 1,\n             BiasAdjust = TRUE,\n             Weight = 2)\nsummary(att)\n\nOur output estimate will be the ATT - the average treatment effect for those units who received the treatment.",
    "crumbs": [
      "Selection on Observables",
      "Propensity Score Matching"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Resources on Causal Inference",
    "section": "",
    "text": "This repository contains resources on causal inference, and applying causal inference methods to political science and political economy.\n\nUse the top navigation bar to navigate between different methods.\nUse the side navigation bar to navigate within a method.\nR-code for implementation is included.\nI have tried to keep up with modern advancements, including the recent difference-in-differences rennaisance.\n\nThese resources have been collected throughout my postgraduate degree at the London School of Economics. I hope these resources can be useful for my future self and others.\nI try to ensure everything in this repository is accurate. If there are any issues with the repository, let me know.\nFor a collection of statistical resources, see http://kevinli03.github.io/stats\nFor my personal website, see http://kevinli03.github.io",
    "crumbs": [
      "Home",
      "Homepage"
    ]
  },
  {
    "objectID": "regress.html",
    "href": "regress.html",
    "title": "Linear Regression Estimator",
    "section": "",
    "text": "See the pros and cons of this estimator in the choosing an estimator page.\n\nSelection on observables is about controlling for confounders. Linear regression is a very natural way to control for confounders.\n\\[\nY_i = \\beta_0 + \\beta_1X_{i1} + \\beta_2 X_{i2} + \\eps_i\n\\]\nWe know that in the above equation, \\(\\beta_1\\) is the relationship between \\(X_i\\) and \\(Y_i\\), while controllling (holding constant) \\(X_2\\).\nUsing this idea, we can implement causal inference with regression, with one of the explanatory variables being our treatment variable, and the rest of the explanatory variables being control variables.\n\\[\nY_i = \\alpha + D_i\\tau + \\b X_i' \\b\\beta + \\eps_i\n\\]\n\nWhere \\(\\alpha\\) is the intercept and \\(\\b X_i\\) is a vector of confounder values for individual \\(i\\).\n\nOur ordinary least squares (OLS) estimate \\(\\widehat\\tau\\) is an unbiased estimator of the true \\(\\tau_{ATE}\\) given three conditions are met:\n\nWe meet the selection on observables assumption of conditional ignorability. Conditional ignorability implies exogeneity, which means the estimate is unbiased.\nThe relationship between our continuous confounders and outcome variable is linear. This is because if the true relationship between these two is not linear, then our linear model is wrong, so it is not properly controlling for confounders.\nThere is no heterogeneity in treatment effects. Angrist (1998), Lin (2013), and Słoczyński (2022) have proven that when there is heterogeneity, OLS is estimating another quantity that is not the ATE.\n\n\nHeterogeneity means that different individuals have different individual treament effects \\(\\tau_i\\). OLS only estimates the ATE if there is homogeneity - all \\(\\tau_i\\) are equal.\n\n\nBefore you implement the estimator, make sure you have reasons to believe you meet the neccessary assumptions for selection on observables.\nWe will need the fixest package:\n\nlibrary(fixest)\n\nTo run a regression estimator, we do:\n\nfeols(Y ~ D + X1 + X2 + X3,\n      data = data,\n      se = \"hetero\")\n\n\nWe typically assume heteroscedasticity, so we use heteroscedasticity-robust standard errors. If you can prove homoscedasticity, then you can use normal standard errors.\n\nThe coefficient for the treatment variable will be the ATE - the average treatment effect for all units in the study.\n\nAssuming you have met all the assumptions of selection on observables, and the special assumptions for the linear regression estimator shown above.",
    "crumbs": [
      "Selection on Observables",
      "Linear Regression Estimator"
    ]
  },
  {
    "objectID": "distance.html",
    "href": "distance.html",
    "title": "Distance Matching",
    "section": "",
    "text": "See the pros and cons of this estimator in the choosing an estimator page.\n\nMia is in our study and receives the treatment. Mia’s causal effect is:\n\\[\n\\tau_{\\text{Mia}} = \\textcolor{purple}{Y^{(1)}_\\text{Mia}} - \\textcolor{red}{Y^{(0)}_\\text{Mia}}\n\\]\nWe cannot observe Mia’s counterfactual (in red). However, what we can do is to find an untreated individual similar to Mia to approximate Mia’s counterfactual:\n\\[\n\\tau_{\\text{Mia}} \\approx \\textcolor{purple}{Y^{(1)}_\\text{Mia}} - \\textcolor{purple}{Y^{(0)}_\\text{Matched individual}}\n\\]\nDistance matching matches an individual that is treated (like Mia) with one that is not treated based on how close their confounding values are. We define closeness by Mahalanobis distance:\n\\[\n\\delta_{i, j} = \\sqrt{(\\b x_i - \\b x_j)' \\ \\b\\Sigma_x^{-1} (\\b x_i - \\b x_j)}\n\\]\n\nWhere \\(i\\) and \\(j\\) are two units we want to measure the distance between, \\(\\b x\\) is a vector of confounder values, and \\(\\b\\Sigma_x\\) is the covariance matrix of confounders.\n\nBecause distance matching depends on finding matches in a n-dimensional space, it is subject to the curse of dimensionality. This essentially means that the more confounders you have, the more dimensions you have to match over, and the harder it is to find good matches. So we typically do not use any more than 3-5 confounders with distance matching.\n\nBad matches means incorrectly using someone’s counterfactual, resulting in bad estimates.\n\n\nBefore you implement distance matching, make sure you have reasons to believe you meet the neccessary assumptions for selection on observables.\nWe will need the Matching package.\n\nlibrary(Matching)\n\nNow, we can implement the matching as follows.\n\natt &lt;- Match(Y = my_data$Y,\n             Tr = my_data$D,\n             X = my_data[,c(\"X1\",\"X2\", \"X3\")],\n             M = 1,\n             BiasAdjust = TRUE,\n             Weight = 2)\nsummary(att)\n\nOur output estimate will be the ATT - the average treatment effect for those units who received the treatment.",
    "crumbs": [
      "Selection on Observables",
      "Distance Matching"
    ]
  },
  {
    "objectID": "soochoose.html",
    "href": "soochoose.html",
    "title": "Choosing an Estimator",
    "section": "",
    "text": "We know how selection on observables works now. But how do we actually implement selection on observables? Below are a list of estimators and their strengths/weaknesses. You can use multiple simultaneously for robustness.\n\nLinear Regression Estimator\n\nEstimand: ATE\nPros: very simple, works well with small datasets.\nCons: 1) requires linear relationship between confounders and outcome, 2) does not work when there are heterogenous treatment effects.\n\n\nKevin’s Comments: since heterogeneity is so common in almost everything, I would recommend against using this estimator unless nothing else is possible. The fully interacted estimator (below) is just a better version of this.\n\n\n\nFully Interacted Estimator\n\nEstimand: ATE\nPros: 1) modified regression to allow for heterogenous effects, 2) still relatively simple.\nCons: requires linear relationship between confounders and outcome\n\n\n\nDistance Matching\n\nEstimand: ATT\nPros: 1) non-parametric, so no need to assume the type of relationship between confounders and outcome. 2) relatively intuitive idea.\nCons: 1) can be badly biased when more than 3-5 confounders, 2) throws out unmatched data so wastes data.\n\n\nKevin’s Comments: there is little reason to use distance matching over genetic matching, unless your machine physically cannot estimate genetic matching.\n\n\n\nPropensity Score Matching\n\nEstimand: ATT\nPros: 1) non-parametric, so no need to assume the type of relationship between confounders and outcome, 2) can handle larger amounts of confounders than distance matching.\nCons: 1) needs a large sample size to not be biased, 2) throws out unmatched data so wastes data.\n\n\nKevin’s Comments: there is little reason to use propensity score matching over genetic matching, unless your machine physically cannot estimate genetic matching.\n\n\n\nGenetic Matching\n\nEstimand: ATT\nPros: 1) non-parametric, so no need to assume the type of relationship between confounders and outcome, 2) shown to be the best matching estimator\nCons: 1) throws out unmatched data so wastes data, 2) can be computationally taxing.\n\n\n\nInverse Probability Weighting\n\nEstimand: ATE\nPros: 1) non-parametric, so no need to assume the type of relationship between confounders and outcome, 2) does not waste data like matching methods do.\nCons: requires a large sample size to be unbiased.",
    "crumbs": [
      "Selection on Observables",
      "Choosing an Estimator"
    ]
  },
  {
    "objectID": "frameworks.html",
    "href": "frameworks.html",
    "title": "Basics of Causality",
    "section": "",
    "text": "This page covers the potential outcomes framework and the causal estimands.\n\nIn causal inference, we are interested in causal questions:\n\n\n\n\n\n\n\n\nexample1\n\n\n\nD\n\nTreatment (D)\n\n\n\nY\n\nOutcome (Y)\n\n\n\nD-&gt;Y\n\n\nCausal Effect\n\n\n\n\n\n\n\n\n\n\nWe generally assume the treatment \\(D\\) is binary.\n\nImagine we have two hypothetical parallel worlds that are copies of each other. Both of these worlds are identical except for one aspect: the treatment:\n\n\n\n\n\n\n\n\nParallel World\nTreatment\nPotential Outcome\n\n\nKevin does not Receive Treatment\n\\(D_\\text{Kevin} = 0\\)\n\\(\\purple{Y_\\text{Kevin}^{(0)}}\\)\n\n\nKevin Receives Treatment\n\\(D_\\text{Kevin} = 1\\)\n\\(\\purple{Y_\\text{Kevin}^{(1)}}\\)\n\n\n\n\nThe only difference between the two worlds is the treatment. Thus, any difference in outcomes between the two worlds must be the causal effect of the treatment.\n\\[\n\\tau_\\text{Kevin} = \\purple{Y_\\text{Kevin}^{(1)}} - \\purple{Y_\\text{Kevin}^{(0)}}\n\\]\n\nTechnically, we need another assumption, SUTVA, for this to be true. I will explain this assumption as part of the identification assumptions.\n\nHowever, in reality, we do not have two parallel worlds. Thus, by definition, one of the potential outcomes is not observed in our real world - the counterfactual.\n\n\n\n\n\n\n\n\nIn the Real World\nObserved Outcome\nCounterfactual\n\n\nKevin receives treatment (treated)\n\\(Y_\\text{Kevin}= \\purple{Y_\\text{Kevin}^{(1)}}\\)\n\\(\\red{Y_\\text{Kevin}^{(0)}}\\)\n\n\nKevin did not receive treatment (untreated)\n\\(Y_\\text{Kevin} = \\purple{Y_\\text{Kevin}^{(0)}}\\)\n\\(\\red{Y_\\text{Kevin}^{(1)}}\\)\n\n\n\n\nThe fundamental problem of causal inference is that in order to calculate our individual treatment effect \\(\\tau\\), we need both potential outcomes. Our goal is to estimate causal effects without observing counterfactuals. This is difficult at the individual level, so instead, we focus on average treatment effects for groups:\n\n\n\n\n\n\n\n\nGroup Effects\nNotation\nDefinition\n\n\nAverage Treatment Effect (ATE)\n\\(\\tau_\\text{ATE}\\)\nThe average treatment effects for all individuals in our study (treated and untreated).\n\n\nAverage Treatment Effect on the Treated (ATT)\n\\(\\tau_\\text{ATT}\\)\nThe average treatment effect but only for individuals who receive the treatment in our study.\n\n\nLocal Average Treatment Effect (LATE)\n\\(\\tau_\\text{LATE}\\)\nThe average treatment effect but only for a specific (local) group of individuals in a study.",
    "crumbs": [
      "Home",
      "Basics of Causality"
    ]
  },
  {
    "objectID": "soo.html",
    "href": "soo.html",
    "title": "Selection on Observables",
    "section": "",
    "text": "Our issue in causal inference is that a confounder is causing pre-existing differences:\n\n\n\n\n\n\n\n\nexample2\n\n\n\nD\n\nReceiving Scholarship\n\n\n\nY\n\nUniversity Grades\n\n\n\nD-&gt;Y\n\n\nCausal Effect\n\n\n\nX\n\nIntellegence (Confounder)\n\n\n\nX-&gt;D\n\n\n\n\n\nX-&gt;Y\n\n\n\n\n\n\n\n\n\n\n\n\nBy definition, as the confounder changes, your likelihood of getting treatment changes. As the confounder changes, the outcome value will also change.\nThese issues occur when the confounder changes in value. So what if we hold the confounders constant? Then, there would be no changes in confounders - so the variation in treatment assignment and outcomes cannot be attributed to the confounder.\nFor example, let’s assume that intellegence has two values: smart and dumb. Let us calculate the treatment effect within each level of intellegence:\n\\[\n\\tau_\\text{smart} = \\purple{\\mean Y_\\text{smart}^{(1)}} - \\purple{\\mean Y_\\text{smart}^{(0)}}\n, \\quad \\tau_\\text{dumb} = \\purple{\\mean Y_\\text{dumb}^{(1)}} - \\purple{\\mean Y_\\text{dumb}^{(0)}}\n\\]\nThe confounder is constant here, so no selection bias. Thus, within each category, correlation is equal to causation. Our overall causal effect will be a weighted average of the categories:\n\\[\n\\tau = \\tau_\\text{smart} Pr(\\text{smart})  \\ + \\ \\tau_\\text{dumb} Pr(\\text{dumb})\n\\]\n\nThe weights of this weighted average are the probability/frequency of that value of the confounder.\n\nObviously, most confounders have more than 2 categories, and we often have more confounders. But the same intuition applies. Given a set of confounders \\(\\set X\\), we first calculate the treatment effect within a specific vector of confounder values \\(\\b x\\):\n\\[\n\\tau(\\b x) = (\\T - \\C)| \\b x\n\\]\nAnd then, we find the weighted average for the total effect, with the weights being the frequency of that specific vector of confounder values:\n\\[\n\\tau_{ATE} = \\sum \\tau(\\b x) \\cdot Pr(\\b x)\n\\]\nFor selection on observables to work, we need to meet 3 assumptions:\n\n\n\n\n\n\n\nAssumption\nDescription\n\n\nConditional Ignorability\nThis means that we must account for all possible confounders (cannot miss a single one).\n\n\nCommon Support\nThis means no one can have a 100% chance of being in treatment or control. They always have a chance to be in either, no matter their confounding values.\n\n\nStable Unit Treatment Value Assumption (SUTVA)\nThis means that if Ava is treated, that does not affect Mia’s outcome (and for any other 2 individuals).\n\n\n\n\nWe have a wide choice of estimators that we can use. Use the sidebar or links in the table to access each estimator’s page.",
    "crumbs": [
      "Selection on Observables"
    ]
  },
  {
    "objectID": "ipw.html",
    "href": "ipw.html",
    "title": "Inverse Probability Weighting",
    "section": "",
    "text": "See the pros and cons of this estimator in the choosing an estimator page.\n\nLet us look at this example, with a confounder.\n\n\n\n\n\n\n\n\nexample2\n\n\n\nD\n\nReceiving Scholarship\n\n\n\nY\n\nUniversity Grades\n\n\n\nD-&gt;Y\n\n\nCausal Effect\n\n\n\nX\n\nSmartness (Confounder)\n\n\n\nX-&gt;D\n\n\n\n\n\nX-&gt;Y\n\n\n\n\n\n\n\n\n\n\n\n\nLet’s pretend there are only dumb and smart people (for simplicity). Our treated and control groups might be:\n\n\n\n\n\n\n\nTreated (Got Scholarship)\nUntreated (Did not get scholarship)\n\n\nSmart Students (x4)\nSmart Students (x1)\n\n\nDumb Students (x1)\nDumb Students (x4)\n\n\n\nOur two groups have pre-existing differences. However, by emphasising certain individuals, we can make it seem like there are no more imbalances. For example, weighting might make our above table become:\n\n\n\n\n\n\n\nTreated (Got Scholarship)\nUntreated (Did not get scholarship)\n\n\nSmart Students (x4)\nSmart Students (emphasise to x4)\n\n\nDumb Students (emphasise to x4)\nDumb Students (x4)\n\n\n\n\nSee how the underrepresented individuals in each group (treated/untreated) were weighted upwards. More technically, inverse probability weighting emphasises/weights an individual by the inverse of their likelihood to receive treatment.\n\nWe can see there is no more pre-existing differences after weighting. Thus, selection bias has been solved.\n\nBefore you inverse probability weighting, make sure you have reasons to believe you meet the neccessary assumptions for selection on observables:\nWe will need the estimatr package:\n\nlibrary(estimatr)\n\nTo estimate the propensity scores and weights, we can use the glm() command:\n\npropensity &lt;- glm(D ~ X1 + X2,\n                  data = my_data,\n                  family = \"binomial\")\nmy_data$pscore &lt;- predict(propensity, type = \"response\")\nmy_data$ipw &lt;- ifelse(mydata$D == 1,\n                      1/my_data$pscore,\n                      1/(1-my_data$pscore))\n\nFinally, we need to use the lm_robust() command to estimate our causal effects:\n\nate &lt;- estimatr::lm_robust(Y ~ D, data = my_data, weights = ipw)\nsummary(ate)\n\nThe output will be the ATE - the average treatment effect for all units in the study.",
    "crumbs": [
      "Selection on Observables",
      "Inverse Probability Weighting"
    ]
  },
  {
    "objectID": "interact.html",
    "href": "interact.html",
    "title": "Fully Interacted Estimator",
    "section": "",
    "text": "See the pros and cons of this estimator in the choosing an estimator page.\n\nFrom selection on observables, we know that our causal effect is a weighted average:\n\\[\n\\tau_\\text{ATE} = \\sum\\tau (\\b x) Pr(\\b x)\n\\]\nNotice how the weights are the probability of the confounder values of \\(\\b x\\). With some complex math (Angrist 1998), we can actually show that OLS actually estimates:\n\\[\n\\hat\\beta_\\text{OLS} = \\sum \\tau(\\b x) \\frac{Var(D_i | \\b x)Pr(\\b x)}{\\sum Var(D_i | \\b x^c)Pr(\\b x^c)}\n\\]\n\nWhere \\(\\b x^c\\) is the complement (not \\(\\b x\\)).\n\nThese weights are not equivalent to the selection on observables \\(\\tau_{ATE}\\). Thus, if not all \\(\\tau(\\b x)\\) are exactly the same (which implies heterogeneity), then our linear regression estimator will incorrectly estimate the ATE.\nHeterogeneity is present in almost all situations we are interested in. Lin (2013) proposes the fully interacted estimator, which allows for consistent estimation of the ATE even with heterogeneity:\n\\[\nY_i = \\alpha + D_i \\tau + (\\b{X}_i - \\mean{\\b X})' \\b\\beta \\ + D_i (\\b X_i - \\mean{\\b X})' \\b\\gamma \\  + \\eps_i\n\\]\n\n\\(\\mean{\\b X}\\) is a vector of the means of each confounder. \\(\\tau\\) is the estimate of the ATE. See Lin (2013) for proofs.\n\nThe new OLS estimate of \\(\\hat\\tau\\) in this estimator will technically still be a biased estimator of \\(\\tau_{ATE}\\), but the bias is negligible.\n\nBefore you implement the estimator, make sure you have reasons to believe you meet the neccessary assumptions for selection on observables.\nWe will need the estimatr package:\n\nlibrary(estimatr)\n\nThen, we can use the lm_lin() function to estimate:\n\nate &lt;- estimatr::lm_lin(Y ~ D,\n                        covariates = ~ X1 + X2 + X3,\n                        data = my_data)\nsummary(ate)\n\nThe output will be the ATE - the average treatment effect for all units in the study.",
    "crumbs": [
      "Selection on Observables",
      "Fully Interacted Estimator"
    ]
  },
  {
    "objectID": "genetic.html",
    "href": "genetic.html",
    "title": "Genetic Matching",
    "section": "",
    "text": "See the pros and cons of this estimator in the choosing an estimator page.\n\nMia is in our study and receives the treatment. Mia’s causal effect is:\n\\[\n\\tau_{\\text{Mia}} = \\textcolor{purple}{Y^{(1)}_\\text{Mia}} - \\textcolor{red}{Y^{(0)}_\\text{Mia}}\n\\]\nWe cannot observe Mia’s counterfactual (in red). However, what we can do is to find an untreated individual similar to Mia to approximate Mia’s counterfactual:\n\\[\n\\tau_{\\text{Mia}} \\approx \\textcolor{purple}{Y^{(1)}_\\text{Mia}} - \\textcolor{purple}{Y^{(0)}_\\text{Matched individual}}\n\\]\nLike distance matching, genetic matching matches an individual that is treated (like Mia) with one that is not treated based on how close their confounding values are. However, genetic matching uses a slightly different variation of mahalanobis distance:\n\\[\n\\delta_{i, j}(\\b W) = \\sqrt{(\\b x_i - \\b x_j)' \\ (\\b\\Sigma_x^{-\\frac{1}{2}})' \\ \\b W \\ \\b\\Sigma_x^{-\\frac{1}{2}}  (\\b x_i - \\b x_j)}\n\\]\n\nWhere \\(i\\) and \\(j\\) are two units we want to measure the distance between, \\(\\b x\\) are their confounder values, and \\(\\b\\Sigma_x\\) is the covariance matrix of confounders. \\(\\b W\\) is a weights matrix.\n\nThe weights \\(\\b W\\) are estimated to make the treated and untreated groups as similar as possible. This balance between treated and untreated eliminates selection bias. Then, matching is done with the units that have the smallest distance.\n\nBefore you start genetic matching, make sure you have reasons to believe you meet the neccessary assumptions for selection on observables:\nWe will need the Matching and MatchIt package.\n\nlibrary(Matching)\n\nFirst, we need to estimate the propensity scores with a logistic regression.\n\nIt is recommended to use the propensity score as one of the controls on which to genetic match on.\n\n\npropensity &lt;- glm(D ~ X1 + X2,\n                  data = my_data,\n                  family = \"binomial\")\nmy_data$pscore &lt;- predict(propensity,\n                          type = \"response\")\n\nThen, we use the GenMatch() function to estimate a weights matrix \\(\\b W\\):\n\nset.seed(333) #any number works\ngen &lt;- GenMatch(Tr = my_data$D,\n                    X = my_data[,c(\"X1\",\"X2\",\"pscore\")],\n                    BalanceMatrix = my_data[,c(\"X1\",\"X2\")],   \n                    estimand = \"ATT\",\n                    M = 2,\n                    replace = TRUE,\n                    ties = FALSE,\n                    distance.tolerance = 0,\n                    print.level = 0,\n                    pop.size = 200)\n\n\nYou can increase pop.size to increase the accuracy - but it will increase the time and computational power needed.\n\nNow, let us conduct estimation with genetic matching:\n\natt &lt;- Match(Y = my_data$Y,\n             Tr = my_data$D,\n             X = my_data[,c(\"X1\",\"X2\",\"pscore\")],\n             estimand = \"ATT\",\n             M = 2,\n             replace = TRUE,\n             ties = FALSE,\n             distance.tolerance = 0,\n             Weight.matrix = gen$Weight.matrix,\n             Weight = 3)\n\nOur output estimate will be the ATT - the average treatment effect for those units who received the treatment.",
    "crumbs": [
      "Selection on Observables",
      "Genetic Matching"
    ]
  }
]