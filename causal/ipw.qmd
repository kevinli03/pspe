---
title: "Inverse Probability Weighting"
---

```{r}
#| message: false
#| warning: false

# Packages Needed:
library(fixest)
```

Let us look at this example, with a confounder.

::: center-graph
```{dot}
//| fig-width: 4
//| fig-height: 1.1
digraph example2 {
  bgcolor="transparent";
  // Nodes
  D [shape=box, pos = "0,0!", label="Receiving Scholarship"]
  X [shape=box, pos = "2,0!", label="Smartness (Confounder)"]
  Y [shape=box, pos = "1,-1!", label="University Grades"]

  // Edges
  {rank=same; D -> Y [label="Causal Effect"]}
  X -> D
  X -> Y [dir=both]
  
  graph [nodesep=0.5, ranksep=0.5]

}
```
:::

Our treated and control groups might look like:

::: small
|                                         |                                                   |
|--------------------------------|----------------------------------------|
| [Treated (Got Scholarship)]{.smallcaps} | [Untreated (Did not get scholarship)]{.smallcaps} |
| Smart Students (x4)                     | Smart Students (x1)                               |
| Dumb Students (x1)                      | Dumb Students (x4)                                |

: {tbl-colwidths="\[50,50\]" .bordered}
:::

Our two groups have pre-existing differences. However, by emphasising certain individuals, we can make it seem like there are no more imbalances:

::: small
|                                         |                                                   |
|--------------------------------|----------------------------------------|
| [Treated (Got Scholarship)]{.smallcaps} | [Untreated (Did not get scholarship)]{.smallcaps} |
| Smart Students (x4)                     | Smart Students (emphasise to x4)                  |
| Dumb Students (emphasise to x4)         | Dumb Students (x4)                                |

: {tbl-colwidths="\[50,50\]" .bordered}
:::

::: small
See how the underrepresented individuals in each group (treated/untreated) were weighted upwards. We can see there is no more pre-existing differences after weighting. Thus, selection bias has been solved.
:::

The weights/emphasis an individual by the inverse of their likelihood to receive treatment. This is estimated as the inverse of the [propensity score](pscore.qmd), which is estimated using **all confounders**.

::: small
Omission of any confounder will cause inaccurate propensity scores, and inaccurate weights.
:::

```{r}
#| echo: false
#| message: false
#| warning: false


library(tidyverse)
N = 1000
ATE = 2
  
df = tibble(
  cov1 = rbinom(N, 1, 0.5),
  cov2 = rnorm(N),
  P = rnorm(N),
  U = rnorm(N), 
  W = rnorm(N),
) %>%
  mutate(
    Y0 = 1 + 0.5*cov1 + 0.5*cov2 + 0.5*P + 0.5*U,
    Y1 = Y0 + rnorm(N, mean = ATE*1.5, sd = 1)*cov1 + rnorm(N, mean = ATE/2)*(1-cov1)
  )

df = df %>%
  mutate(
    U2 = rnorm(N),
    pscore = 1/(1 + exp(-(-1 - 2*cov1 - 1.5*cov2 + 1.5*W + 0.5*U2))),
    treatment = rbinom(N, 1, pscore),
    outcome = Y1*treatment + Y0*(1-treatment)
  )
```

```{r}
#| warning: false
#| message: false
#| comment: "#>"
#| class-output: r

# Logistic Model for Propensity Scores
propensity <- feglm(
  treatment ~ cov1 + cov2,
  data = df,
  family = "binomial")

# Predice Propensity Scores for All Observations
df$pscore <- predict(propensity, type = "response")

# inverse of propensity score for weights:
df$ipw <- ifelse(df$treatment == 1, 1/df$pscore, 1/(1-df$pscore))
```

Now with the weights, we can estimate the causal effect with a regression:

```{r}
#| warning: false
#| message: false
#| comment: "#>"
#| class-output: r

model <- feols(outcome ~ treatment, data = df, weights = ~ipw)
coeftable(model) # Can also use summary(model)
```

::: small
The treatment estimate is our ATE.
:::

If [all confounders are included]{.underline} in the propensity score estimation, the estimate will be equal to the $\ate$.

Because weighting is dependent on the estimation of propensity scores, it is sensitive to poorly estimated propensity scores with the logistic regression, This tends to happen with smaller sample sizes, so the IPW estimator can be poor in small sample sizes.
